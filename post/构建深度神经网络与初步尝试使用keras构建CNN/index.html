<!DOCTYPE html>
<html>
  <head>
      
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<title>Tudouvvv</title>
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

<meta name="description" content="äººç”Ÿè¿˜é•¿ï¼Œæ…¢æ…¢æ¥"/>
<meta name="keywords" content="äººç”Ÿè¿˜é•¿ï¼Œæ…¢æ…¢æ¥"/>

<!-- Place favicon.ico and apple-touch-icon.png in the root directory -->
<link rel="shortcut icon" href="https://tudouvvv.github.io//favicon.ico">

<link rel="stylesheet" href="https://tudouvvv.github.io//styles/main.css">

<!-- Modernizr JS -->
<script src="https://tudouvvv.github.io//media/scripts/_vendors/modernizr-2.6.2.min.js"></script>
<!-- FOR IE9 below -->
<!--[if lt IE 9]>
<scripts src="https://tudouvvv.github.io//media/scripts/_vendors/respond.min.js"></scripts>
<![endif]-->

<!-- Comment -->


<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/tomorrow-night.min.css">
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/highlight.min.js"></script>
<link crossorigin="anonymous" integrity="sha384-50oBUHEmvpQ+1lW4y57PTFmhCaXp0ML5d60M1M7uH2+nqUivzIebhndOJK28anvf" href="https://lib.baomitu.com/font-awesome/5.8.1/css/all.min.css" rel="stylesheet">

  </head>
  <body>
  
<div id="fh5co-offcanvas">
    <a href="#!" class="fh5co-close-offcanvas js-fh5co-close-offcanvas">
        <span><i class="icon-cross3"></i> <span>Close</span></span>
    </a>
    <div class="fh5co-bio">
        <figure>
            <img src="https://tudouvvv.github.io//media/images/avatar.png" alt="Tudouvvv" class="img-responsive">
        </figure>
        <h3 class="heading">ABOUT ME</h3>
        <h2>Tudouvvv</h2>
        <p>äººç”Ÿè¿˜é•¿ï¼Œæ…¢æ…¢æ¥</p>
        <ul class="fh5co-social">
            
                <li>
                    
                </li>
            
                <li>
                    
                </li>
            
                <li>
                    
                </li>
            
                <li>
                    
                </li>
            
                <li>
                    
                </li>
            
        </ul>
    </div>

    <div class="fh5co-menu">
        <div class="fh5co-box">
            <h3 class="heading">æœç´¢</h3>
            <form action="#">
                <div class="form-group">
                    <input type="text" class="form-control" placeholder="è¾“å…¥å…³é”®å­—">
                </div>
            </form>
        </div>
        <div class="fh5co-box">
            <h3 class="heading">æ ‡ç­¾</h3>
            <ul>
                
                    <li><a href="https://tudouvvv.github.io//tag/leetcode">Leetcode</a></li>
                
                    <li><a href="https://tudouvvv.github.io//tag/python">Python</a></li>
                
                    <li><a href="https://tudouvvv.github.io//tag/keras">Keras</a></li>
                
                    <li><a href="https://tudouvvv.github.io//tag/mysql">Mysql</a></li>
                
                    <li><a href="https://tudouvvv.github.io//tag/code">Code</a></li>
                
                    <li><a href="https://tudouvvv.github.io//tag/Ejc-I2BJt">Life</a></li>
                
            </ul>
        </div>
    </div>
</div>

<header id="fh5co-header">
    <div class="container-fluid">
        <div class="row">
            <a href="#" class="js-fh5co-nav-toggle fh5co-nav-toggle"><i></i></a>
            <ul class="fh5co-social">
                
                    <li>
                        <a href="/"
                         >
                            é¦–é¡µ
                        </a>
                    </li>
                
                    <li>
                        <a href="/archives"
                         >
                            å½’æ¡£
                        </a>
                    </li>
                
                    <li>
                        <a href="/tags"
                         >
                            æ ‡ç­¾
                        </a>
                    </li>
                
                    <li>
                        <a href="/post/about"
                         >
                            å…³äº
                        </a>
                    </li>
                
            </ul>
            <div class="col-lg-12 col-md-12 text-center">
                <h1 id="fh5co-logo">
                    <a href="https://tudouvvv.github.io/">Tudouvvv</a>
                </h1>
            </div>
        </div>
    </div>
</header>


<!--  <a href="#" class="fh5co-post-prev"><span>ğŸ‘ˆ Prev</span></a>-->
<!--  <a href="#" class="fh5co-post-next"><span>Next ğŸ‘‰</span></a>-->

  <div class="container-fluid">
      <div class="row fh5co-post-entry single-entry">
          <article class="col-lg-8 col-lg-offset-2 col-md-8 col-md-offset-2 col-sm-8 col-sm-offset-2 col-xs-12 col-xs-offset-0">
              <figure class="animate-box">
                  
                      <img src="https://raw.githubusercontent.com/Tudouvvv/Pic_path/master/2018-11-14-banner.jpg" alt="æ„å»ºå¤šå±‚ç¥ç»ç½‘ç»œä¸åˆæ­¥å°è¯•ä½¿ç”¨kerasæ„å»ºCNN" class="img-responsive">
                  
              </figure>
              <span class="fh5co-meta animate-box">
                  
                      <div class="tag-container">
                          
                              <a href="https://tudouvvv.github.io//tag/python" class="tag">Python, </a>
                          
                              <a href="https://tudouvvv.github.io//tag/keras" class="tag">Keras, </a>
                          
                      </div>
                  
              </span>
              <h2 class="fh5co-article-title animate-box">æ„å»ºå¤šå±‚ç¥ç»ç½‘ç»œä¸åˆæ­¥å°è¯•ä½¿ç”¨kerasæ„å»ºCNN</h2>
              <span class="fh5co-meta fh5co-date animate-box">2018-11-14</span>

              <div class="col-lg-12 col-lg-offset-0 col-md-12 col-md-offset-0 col-sm-12 col-sm-offset-0 col-xs-12 col-xs-offset-0 text-left content-article">
                  <div class="row">
                      <div class="col-md-12 animate-box post-content">
                          <p> <p>æ­£å‡†å¤‡å¼€å§‹å†™è¿™ç¯‡è®°å½•ï¼Œç»“æœå‘ç°å›¾åºŠåäº†- -ï¼Œåˆå¼€å§‹ä»åŸæ¥çš„å›¾åºŠæŠŠä¹‹å‰çš„å›¾ç‰‡è½¬ç§»åˆ°æ–°çš„å›¾åºŠï¼Œæµªè´¹äº†å¥½å¤šæ—¶é—´ã€‚</p>
<p>ä¸Šæ¬¡ç”¨logesticå›å½’å’Œæ¢¯åº¦ä¸‹é™æ³•è®­ç»ƒäº†ä¸€ä¸ªç¥ç»ç½‘ç»œï¼Œç”¨æ¥åšäºŒåˆ†ç±»çš„é—®é¢˜ï¼Œæœ€åç²¾åº¦å·®ä¸å¤š70%å·¦å³ï¼Œè¿™æ¬¡ä¸»è¦å†™ä¸€ä¸ªå¤šå±‚çš„ç¥ç»ç½‘ç»œï¼Œè®­ç»ƒåŒæ ·çš„æ•°æ®é›†ï¼Œçœ‹ä¸€çœ‹ä¼šä¸ä¼šå¯¹å‡†ç¡®åº¦æœ‰æå‡ã€‚</p>
<h1 id="å¤šå±‚ç¥ç»ç½‘ç»œ">å¤šå±‚ç¥ç»ç½‘ç»œ</h1>
<p>å¤šå±‚ç¥ç»ç½‘ç»œä¸­ï¼Œä¹Ÿåˆ†ä¸ºå‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­ï¼Œå‰å‘ä¼ æ’­è®¡ç®—æŸå¤±å‡½æ•°ï¼Œåå‘ä¼ æ’­é€šè¿‡æ¢¯åº¦ä¸‹é™æ³•æ¥æ›´æ–°å‚æ•°ã€‚åœ¨æ¯ä¸€å±‚ä¸­ï¼Œå…ˆé€šè¿‡ä¸€ä¸ªçº¿æ€§çš„æ¿€æ´»å•å…ƒ<code>Z = WX + b</code>ï¼Œç„¶åå†é€šè¿‡ä¸€ä¸ªéçº¿æ€§çš„æ¿€æ´»å•å…ƒï¼Œè¿™é‡Œçš„è¯ç”±äºæˆ‘ä»¬åšçš„æ˜¯äºŒåˆ†ç±»é—®é¢˜ï¼Œæ‰€ä»¥æœ€åä¸€å±‚çš„æ¿€æ´»å‡½æ•°é€‰æ‹©<code>sigmoid</code>ï¼Œå…¶å®ƒå±‚ä¸­é€‰æ‹©æ•ˆæœæ¯”è¾ƒå¥½çš„<code>Relu</code>å‡½æ•°ï¼Œåœ¨å®é™…çš„æ“ä½œä¸­ï¼Œå¯¹äºä¸€ä¸ªLå±‚çš„ç¥ç»ç½‘ç»œï¼Œæˆ‘ä»¬éœ€è¦è¿›è¡Œ<code>L-1</code>æ¬¡Reluå‡½æ•°æ¿€æ´»ã€‚</p>
<p>è¿™æ˜¯å¤šå±‚ç¥ç»ç½‘ç»œçš„å¤§æ¦‚ç»“æ„ï¼š<br>
<img src="https://raw.githubusercontent.com/Tudouvvv/Pic_path/master/%E5%A4%9A%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.png" alt=""></p>
<p>å‰å‘è¿‡ç¨‹å°±æ˜¯ä¸æ–­çš„é€šè¿‡å„å±‚ç¥ç»ç½‘ç»œç›´åˆ°æœ€åè®¡ç®—æŸå¤±ï¼Œæœ€ä¸»è¦çš„å°±æ˜¯åå‘è¿‡ç¨‹ï¼Œåå‘è¿‡ç¨‹å°±æ˜¯é“¾å¼æ±‚å¯¼ä»¥ä¾¿æœ€åä½¿ç”¨æ¢¯åº¦ä¸‹é™æ³•æ¥æ›´æ–°æ¯ä¸€å±‚çš„å‚æ•°</p>
<p>å¯¹å‰å‘è¿‡ç¨‹æ¥è¯´ï¼š</p>
<p><img src="https://raw.githubusercontent.com/Tudouvvv/Pic_path/master/%E5%89%8D%E5%90%91%E8%BF%87%E7%A8%8B.png" alt=""></p>
<p>å³æ ¹æ®ä¸Šä¸€å±‚çš„æ¿€æ´»å€¼é€šè¿‡çº¿æ€§å•å…ƒå’Œæ¿€æ´»å‡½æ•°è¾“å‡ºæœ¬å±‚çš„æ¿€æ´»å€¼ï¼Œå…¶ä¸­<code>g(Z)</code>ä»£è¡¨æ¯ä¸€å±‚çš„æ¿€æ´»å‡½æ•°ï¼Œè€Œåå‘è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬éœ€è¦è®¡ç®—æ¯ä¸€å±‚<code>dW</code>å’Œ<code>db</code>çš„å€¼ä»¥ä¾¿è¿›è¡Œåé¢çš„å‚æ•°æ›´æ–°ï¼š</p>
<p><img src="https://raw.githubusercontent.com/Tudouvvv/Pic_path/master/%E5%90%8E%E5%90%91%E4%BC%A0%E6%92%AD.png" alt=""></p>
<p>è®²é“ç†ï¼ŒçŸ©é˜µå­¦çš„ä¸æ˜¯å¾ˆå¥½ï¼Œæ‰€ä»¥ä¸€æ—¦æŠŠå˜é‡çŸ©é˜µåŒ–ä»¥åè¿›è¡Œæ±‚å¯¼æ“ä½œä»€ä¹ˆçš„æœ‰ç‚¹è¿·ç³Šï¼Œè¿™é‡Œéœ€è¦å†å¥½å¥½å­¦ä¹ ä¸€ä¸‹</p>
<p>è¿™æ ·å°±æ˜¯æ•´ä¸ªæ·±å±‚ç¥ç»ç½‘ç»œçš„åŸºæœ¬ç»“æ„äº†</p>
<p>æˆ‘ä»¬å¯ä»¥å…ˆæŠŠæ¿€æ´»å‡½æ•°çš„å‰å‘å’Œåå‘è¿‡ç¨‹å†™æˆä¸€ä¸ªæ¨¡å—ï¼Œä»¥ä¾¿æ–¹ä¾¿è°ƒç”¨ï¼š</p>
<pre><code class="language-python">import numpy as np


def sigmoid(Z):
    A = 1 / (1 + np.exp(-Z))
    cache = Z
    return A, cache


def sigmoid_backward(dA, cache):
    Z = cache
    s = 1 / (1 + np.exp(-Z))
    dZ = dA * s * (1 - s)
    return dZ


def relu(Z):
    A = np.maximum(0, Z)
    cache = Z
    return A, cache


def relu_backward(dA, cache):
    Z = cache
    dZ = np.array(dA, copy=True)
    dZ[Z &lt;= 0] = 0
    return dZ
</code></pre>
<p>æ¥ç€æ¥å¼€å§‹å†™æˆ‘ä»¬çš„å¤šå±‚ç¥ç»ç½‘ç»œï¼Œç¬¬ä¸€æ­¥æ˜¯å¯¹æˆ‘ä»¬çš„æ•°æ®è¿›è¡Œé¢„å¤„ç†ï¼Œç”±äºæˆ‘ä»¬è¾“å…¥çš„æ˜¯64*64çš„å›¾ç‰‡ï¼Œè€Œä¸”ä¸€å¼ å½©è‰²å›¾ç‰‡æœ‰rgbä¸‰ä¸ªé€šé“ï¼Œæ‰€ä»¥æˆ‘ä»¬è¦æŠŠä¸€å¼ å›¾ç‰‡ä¸Šä¸‰ä¸ªé€šé“çš„ä¿¡æ¯æ•´åˆåœ¨ä¸€èµ·ä½œä¸ºä¸€åˆ—ï¼ŒæŠŠè®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„å›¾ç‰‡çš„ä¿¡æ¯å¤„ç†ä¸ºä¸€ä¸ªçŸ©é˜µï¼Œä½œä¸ºç¥ç»ç½‘ç»œçš„è¾“å…¥ï¼ŒåŒæ—¶å¯ä»¥å¯¹è¾“å…¥æ•°æ®è¿›è¡Œç¼©å°ï¼Œç”±äºåƒç´ å€¼è¡¨ç¤ºäº®åº¦ï¼Œæ¯ç‚¹çš„åƒç´ å€¼æœ€å¤§ä¸º255ï¼Œæˆ‘ä»¬å¯ä»¥æ¯ä¸ªç‚¹çš„åƒç´ å€¼éƒ½é™¤ä»¥255ï¼Œä½¿å¾—æˆ‘ä»¬çš„è¾“å…¥æ•°æ®å…¨éƒ¨åœ¨[0, 1]ä¹‹é—´ã€‚<br>
è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„æ ·æœ¬æ•°æ®æ¥è‡ªå·²ç»å†™å¥½çš„æ¨¡å—ã€‚</p>
<pre><code class="language-python">train_set_x, train_set_y, test_set_x, test_set_y, classes = load_dataset()

train_set_x = train_set_x.reshape(train_set_x.shape[0], -1).T
test_set_x = test_set_x.reshape(test_set_x.shape[0], -1).T

train_set_x = train_set_x / 255
test_set_x = test_set_x / 255
</code></pre>
<p>æ¥ç€åº”è¯¥åˆå§‹åŒ–æˆ‘ä»¬æ¯ä¸€å±‚çš„å‚æ•°ï¼Œä¹‹å‰å¯¹äºåªæœ‰ä¸€ä¸ªlogesticå•å…ƒï¼Œåˆå§‹åŒ–æ—¶å¯ä»¥éƒ½ä¸º0ï¼Œä½†æ˜¯å¯¹å¤šå±‚ç¥ç»ç½‘ç»œæ¥è¯´ï¼Œå¦‚æœWåˆå§‹åŒ–ä¸º0 åˆ™å¯¹äºä»»ä½•Xï¼Œæ¯ä¸ªéšè—å±‚å¯¹åº”çš„æ¯ä¸ªç¥ç»å…ƒçš„è¾“å‡ºéƒ½æ˜¯ç›¸åŒçš„ï¼Œè¿™æ ·å³ä½¿æ¢¯åº¦ä¸‹é™è®­ç»ƒï¼Œæ— è®ºè®­ç»ƒå¤šå°‘æ¬¡ï¼Œè¿™äº›ç¥ç»å…ƒéƒ½æ˜¯å¯¹ç§°çš„ï¼Œæ— è®ºéšè—å±‚å†…æœ‰å¤šå°‘ä¸ªç»“ç‚¹ï¼Œéƒ½ç›¸å½“äºåœ¨è®­ç»ƒåŒä¸€ä¸ªå‡½æ•°ï¼Œæ‰€ä»¥æˆ‘ä»¬è¦é‡‡ç”¨éšæœºåˆå§‹åŒ–ã€‚</p>
<p>åœ¨å¤šå±‚ç¥ç»ç½‘ç»œä¸­ï¼Œæ¯ä¸€å±‚å‚æ•°çš„ç»´åº¦éƒ½æ˜¯ç¡®å®šçš„ï¼Œä¸è¯¥å±‚ç¥ç»å…ƒçš„ä¸ªæ•°å¯†åˆ‡ç›¸å…³ï¼š<br>
<img src="https://raw.githubusercontent.com/Tudouvvv/Pic_path/master/%E5%8F%82%E6%95%B0%E7%BB%B4%E5%BA%A6.png" alt=""></p>
<p>æ‰€ä»¥æˆ‘ä»¬è¿™æ ·æ¥åˆå§‹åŒ–æ¯ä¸€å±‚çš„å‚æ•°ï¼š</p>
<pre><code class="language-python">def initialize_parameters(dims):
    L = len(dims)
    parameters = {}
    for l in range(1, L):
        parameters['W' + str(l)] = np.random.randn(dims[l], dims[l-1]) * np.sqrt(1 / dims[l - 1])
        parameters['b'+ str(l)] = np.zeros((dims[l], 1))
    return parameters
</code></pre>
<p><code>dims</code>ä¸ºä¸€ä¸ªåˆ—è¡¨ï¼Œå…¶ä¸­åŒ…å«æ¯ä¸€å±‚ç¥ç»å…ƒçš„ä¸ªæ•°ï¼Œæ¯”å¦‚<code>[12288, 12, 7, 1]</code></p>
<p>è¿™æ ·å°±åˆå§‹åŒ–å¥½äº†æ¯ä¸€å±‚çš„å˜é‡ï¼Œä¹‹å‰è¯´è¿‡ä¸€ä¸ªå¯¹äºè¯¥å¤šå±‚ç¥ç»ç½‘ç»œæ¥è¯´ï¼Œå‰å‘ä¼ æ’­æ—¶ä¼šè¿›è¡Œ<code>L-1</code>æ¬¡<code>relu</code>æ¿€æ´»ï¼Œä¸€æ¬¡<code>sigmoid</code>æ¿€æ´»ï¼Œæ¯ä¸€æ¬¡æ¿€æ´»åŒ…æ‹¬çº¿æ€§æ¿€æ´»å’Œæ¿€æ´»å‡½æ•°æ¿€æ´»ï¼Œæˆ‘ä»¬æŠŠè¿™ä¸ªæ“ä½œå®šä¹‰æˆä¸€ä¸ªå‡½æ•°ï¼Œåˆ°æ—¶å€™ç›´æ¥è°ƒç”¨å‡½æ•°å°±å¯ä»¥äº†ã€‚</p>
<p>æ‰€ä»¥æ¥ä¸‹æ¥å®šä¹‰æ¯ä¸€å±‚çš„çº¿æ€§æ¿€æ´»éƒ¨åˆ†çš„å‡½æ•°ï¼Œçº¿æ€§æ¿€æ´»éƒ¨åˆ†ä¸»è¦åšçš„å°±æ˜¯<code>Z = WA + B</code>:</p>
<pre><code class="language-python">def linear_forward(A, W, b):
    Z = np.dot(W, A) + b
    linear_cache = (A, W, b)
    return Z, linear_cache
</code></pre>
<p>è¿™é‡Œè¦è®°å¾—ä¿å­˜çº¿æ€§éƒ¨åˆ†çš„å‚æ•°ï¼Œä¹‹ååšæ¢¯åº¦ä¸‹é™æ³•çš„æ—¶å€™ä¼šç”¨åˆ°ã€‚<br>
ç„¶åå°±æ˜¯å®šä¹‰æ¿€æ´»å‡½æ•°æ¿€æ´»çš„å‡½æ•°ï¼Œæ¿€æ´»å‡½æ•°åšçš„å°±æ˜¯<code>A = g(Z)</code>:</p>
<pre><code class="language-python">def activation_forward(A_pre, W, b, activation):
    if activation == 'relu':
        Z, linear_cache = linear_forward(A_pre, W, b)
        A, activation_cache = relu(Z)
    if activation == 'sigmoid':
        Z, linear_cache = linear_forward(A_pre, W, b)
        A, activation_cache = sigmoid(Z)
        
    cache = (linear_cache, activation_cache)
    return A, cache
</code></pre>
<p>åœ¨æ¿€æ´»å‡½æ•°ä¸­è°ƒç”¨ä¹‹å‰å†™çš„çº¿æ€§æ¿€æ´»å‡½æ•°ï¼Œæœ€åè¿”å›æ¯ä¸€å±‚çš„è¾“å‡º<code>A</code>ä»¥åŠå‚æ•°<code>cache</code>ã€‚</p>
<p>æ¥ä¸‹æ¥å°±å¯ä»¥è¿›è¡Œå‰å‘è¿‡ç¨‹çš„ç¼–å†™äº†ï¼Œå‰å‘è¿‡ç¨‹çš„è¾“å…¥æ˜¯æˆ‘ä»¬çš„å›¾ç‰‡ä¿¡æ¯ï¼Œæˆ‘ä»¬ä»¥<code>X</code>è¡¨ç¤ºï¼Œä»¥åŠæ¯ä¸€å±‚çš„å‚æ•°ï¼Œæˆ‘ä»¬ä»¥<code>parameters</code>è¡¨ç¤ºï¼Œè¿™æ ·åœ¨ç»è¿‡æ¯ä¸€å±‚çš„ä¼ æ’­ä¹‹åï¼Œæœ€ç»ˆå¾—åˆ°æˆ‘ä»¬çš„è¾“å‡ºç»“æœ<code>AL</code>ï¼Œæˆ‘ä»¬è¦ç”¨å®ƒæ¥è®¡ç®—æŸå¤±å‡½æ•°çš„å¤§å°ï¼š</p>
<pre><code class="language-python">def L_model_forward(X, parameters):
    caches = []
    A = X
    L = len(parameters) // 2
    for l in range(1, L):
        A_prev = A
        A, cache = activation_forward(A_prev, parameters['W'+str(l)], parameters['b'+str(l)], 'relu')
        caches.append(cache)
        
    AL, cache = activation_forward(A, parameters['W'+str(L)], parameters['b'+str(L)], 'sigmoid')
    caches.append(cache)
    
    return AL, caches
</code></pre>
<p>è¿™æ ·æ•´ä¸ªå‰å‘è¿‡ç¨‹å…¨éƒ¨å®Œæˆï¼Œæ¥ä¸‹æ¥åº”è¯¥è®¡ç®—æŸå¤±å‡½æ•°çš„å¤§å°ï¼Œç”±äºè¿™æ˜¯ä¸€ä¸ªäºŒåˆ†ç±»é—®é¢˜ï¼Œæˆ‘ä»¬é‡‡ç”¨äºŒå…ƒäº¤å‰ç†µä½œä¸ºæˆ‘ä»¬çš„æŸå¤±å‡½æ•°ï¼Œå®ƒçš„è¡¨è¾¾å¼å¦‚ä¸‹ï¼š<br>
<img src="https://raw.githubusercontent.com/Tudouvvv/Pic_path/master/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0.png" alt=""></p>
<pre><code class="language-python">def cost_compute(AL, Y):
    m = Y.shape[1]
    cost = (-1 / m) * np.sum(np.multiply(Y, np.log(AL)) + np.multiply((1 - Y), np.log(1 - AL)))
    cost = np.squeeze(cost)

    return cost
</code></pre>
<p>è¿™å°±æ˜¯æ•´ä¸ªå‰å‘è¿‡ç¨‹çš„æ‰€æœ‰æ­¥éª¤äº†ï¼Œæˆ‘ä»¬ä»¥é™ä½æŸå¤±å‡½æ•°ä¸ºç›®æ ‡ï¼Œåœ¨åå‘è¿‡ç¨‹ä¸­ä¸æ–­ä½¿ç”¨æ¢¯åº¦ä¸‹é™æ³•è¿›è¡Œä¼˜åŒ–ï¼Œé€æ¸é€¼è¿‘æœ€ä½å€¼ï¼Œç›®å‰åªæ˜¯ç®€å•çš„ä½¿ç”¨æ¢¯åº¦ä¸‹é™æ³•ï¼Œåé¢ä¼šå°è¯•å…¶å®ƒçš„ä¼˜åŒ–æ–¹æ¡ˆï¼Œæ¯”å¦‚åŠ¨é‡æ¢¯åº¦ä¸‹é™æˆ–è€…mini-batchã€‚</p>
<p>å®Œæˆæ•´ä¸ªå‰å‘è¿‡ç¨‹ä¹‹åï¼Œæ€è€ƒä¸€ä¸‹åç»­çš„æ­¥éª¤ï¼Œå¯¹äºåå‘è¿‡ç¨‹æ¥è¯´ï¼Œæ¯ä¸€ä¸ªç¥ç»å…ƒå…ˆå¯¹æ¿€æ´»å‡½æ•°æ¿€æ´»çš„éƒ¨åˆ†è¿›è¡Œæ±‚å¯¼å¾—åˆ°<code>dZ</code>ï¼Œç„¶ååœ¨å¯¹çº¿æ€§æ¿€æ´»çš„éƒ¨åˆ†æ±‚å¯¼ï¼Œå¾—åˆ°<code>dW</code>å’Œ<code>db</code>ï¼Œæˆ‘ä»¬é¦–å…ˆå®šä¹‰çº¿æ€§æ¿€æ´»çš„åå‘è¿‡ç¨‹ï¼š</p>
<pre><code class="language-python">def linear_backward(dZ, cache):
    A_prev, W, b = cache
    m = A_prev.shape[1]
    dW = np.dot(dZ, A_prev.T) / m
    db = np.sum(dZ, axis=1, keepdims=True) / m
    dA_prev = np.dot(W.T, dZ)
    return dA_prev, dW, db
</code></pre>
<p>æ¥ç€å®šä¹‰æ¿€æ´»å‡½æ•°æ¿€æ´»çš„åå‘è¿‡ç¨‹ï¼Œæˆ‘ä»¬ä¹‹å‰å·²ç»æŠŠä¸¤ä¸ªæ¿€æ´»å‡½æ•°çš„åå‘æ±‚å¯¼è¿‡ç¨‹å®šä¹‰å¥½äº†ï¼Œæˆ‘ä»¬åªè¦è°ƒç”¨å°±å¥½äº†ã€‚ä¹‹å‰ä¹Ÿè¯´è¿‡ï¼Œæ¯ä¸ªæ¿€æ´»å•å…ƒåˆ†ä¸ºä¸¤ä¸ªè¿‡ç¨‹ï¼Œçº¿æ€§æ¿€æ´»ä¸å‡½æ•°æ¿€æ´»ä¸¤ä¸ªè¿‡ç¨‹ï¼Œæˆ‘ä»¬ç°åœ¨è°ƒç”¨äº†å‡½æ•°æ¿€æ´»çš„åå‘è¿‡ç¨‹ï¼Œå¾—åˆ°<code>dZ</code>ï¼Œç„¶ååœ¨è°ƒç”¨ä¸Šé¢å®šä¹‰çš„çº¿æ€§æ¿€æ´»çš„åå‘è¿‡ç¨‹ï¼Œå¾—åˆ°<code>dA</code>ã€<code>dW</code>ã€<code>db</code>ï¼š</p>
<pre><code class="language-python">def activation_backward(dA, cache, activation):
    linear_cache, activation_cache = cache
    if activation == 'relu':
        dZ = relu_backward(dA, activation_cache)
        dA_prev, dW, db = linear_backward(dZ, linear_cache)
    if activation == 'sigmoid':
        dZ = sigmoid_backward(dA, activation_cache)
        dA_prev, dW, db = linear_backward(dZ, linear_cache)

    return dA_prev, dW, db
</code></pre>
<p>ç„¶åå°±å¯ä»¥æŠŠå…¨éƒ¨è¿‡ç¨‹æ•´åˆåœ¨ä¸€èµ·ï¼Œæˆ‘ä»¬å¯ä»¥æƒ³ä¸€ä¸‹è¿™ä¸ªè¿‡ç¨‹ï¼Œä»æœ€åä¸€ä¸ª<code>sigmoid</code>æ¿€æ´»å•å…ƒæ¥è¯´ï¼Œå®ƒä¼šç»å†ä¸€ä¸ªä¸Šè¿°çš„<code>activation_backward</code>è¿‡ç¨‹ï¼Œå‰ææ˜¯æˆ‘ä»¬éœ€è¦æ±‚å‡ºæŸå¤±å‡½æ•°å¯¹æœ€ç»ˆè¾“å‡ºçš„æ±‚å¯¼å°±å¥½<code>dAL</code>ï¼Œä¹‹åè°ƒç”¨ä¸Šè¿°å‡½æ•°ã€‚ä¹‹åå°±æ˜¯<code>L-1</code>æ¬¡çš„<code>relu</code>å‡½æ•°çš„åå‘ä¼ æ’­è¿‡ç¨‹ï¼Œè¿™æ ·æˆ‘ä»¬å°±ä¼šå¾—åˆ°æ¯ä¸€å±‚å‚æ•°çš„å¯¼æ•°ï¼Œä»¥ä¾¿é€šè¿‡æ¢¯åº¦ä¸‹é™æ³•è¿›è¡Œå‚æ•°çš„æ›´æ–°ï¼š</p>
<pre><code class="language-python">def L_model_backward(AL, Y, caches):
    grads = {}
    L = len(caches)
    m = AL.shape[1]
    Y = Y.reshape(AL.shape)
    dAL = -(np.divide(Y, AL) - np.divide((1 - Y), (1 - AL)))

    current_cache = caches[L - 1]
    grads['dA'+str(L)], grads['dW'+str(L)], grads['db'+str(L)] = activation_backward(dAL, current_cache, 'sigmoid')

    for l in reversed(range(L - 1)):
        current_cache = caches[l]
        grads['dA'+str(l + 1)], grads['dW'+str(l + 1)], grads['db'+str(l + 1)] = activation_backward(grads['dA'+str(l + 2)], current_cache, 'relu')

    return grads
</code></pre>
<p>ç°åœ¨æˆ‘ä»¬æ¥å®šä¹‰å‚æ•°æ›´æ–°çš„å‡½æ•°ï¼Œå‚æ•°æ›´æ–°éœ€è¦å®šä¹‰å­¦ä¹ ç‡<code>learning_rate</code>ï¼Œå®ƒæ§åˆ¶æˆ‘ä»¬æ¯æ¬¡å‚æ•°æ›´æ–°çš„æ­¥é•¿ï¼š</p>
<pre><code class="language-python">def up_parameters(parameters, grads, learning_rate):
    L = len(parameters) // 2
    for l in range(L):
        parameters['W'+str(l+1)] = parameters['W'+str(l+1)] - learning_rate * grads['dW'+str(l+1)]
        parameters['b'+str(l+1)] = parameters['b'+str(l+1)] - learning_rate * grads['db'+str(l+1)]
    return parameters
</code></pre>
<p>è¿™æ ·æ‰€æœ‰çš„è¿‡ç¨‹éƒ½å·²ç»å…¨éƒ¨å®Œæˆäº†ï¼Œæˆ‘ä»¬ç°åœ¨åªéœ€è°ƒç”¨ä¸Šè¿°çš„æ‰€æœ‰è¿‡ç¨‹å°±å¥½ï¼Œæˆ‘ä»¬åŒæ—¶è¿˜å¯ä»¥å®šä¹‰æ¯è¿­ä»£100æ¬¡æ‰“å°å‡ºæ­¤æ—¶çš„æŸå¤±å‡½æ•°çš„å€¼ï¼ŒåŒæ—¶åœ¨è¿­ä»£ç»“æŸåæ‰“å°å‡ºæŸå¤±å‡½æ•°çš„æ›²çº¿ï¼Œçœ‹ä¸€ä¸‹æˆ‘ä»¬çš„è®­ç»ƒè¿‡ç¨‹ï¼š</p>
<pre><code class="language-python">def L_model(X, Y, dims, learning_rate, num_iternation, print_cost=False, isPlot=False):
    parameters = initialize_parameters(dims)
    costs = []
    for i in range(num_iternation):
        AL, caches = L_model_forward(X, parameters)
        cost = cost_compute(AL, Y)
        grads = L_model_backward(AL, Y, caches)
        parameters = up_parameters(parameters, grads, learning_rate)

        if i % 100 == 0:
            costs.append(cost)
            if print_cost:
                print(&quot;ç¬¬&quot;, i + 100, &quot;æ¬¡è¿­ä»£ï¼Œæˆæœ¬å€¼ä¸º:&quot;, np.squeeze(cost))

    if isPlot:
        plt.plot(np.squeeze(costs))
        plt.ylabel('cost')
        plt.xlabel('iterations (per tens)')
        plt.title(&quot;Learning rate =&quot; + str(learning_rate))
        plt.show()
    return parameters
</code></pre>
<p>è¿™æ ·æˆ‘ä»¬å®šä¹‰å¥½ç¥ç»ç½‘ç»œçš„ç»“æ„ï¼Œç›´æ¥è°ƒç”¨è¿™ä¸ªå‡½æ•°å°±å¥½ï¼Œæœ€åæˆ‘ä»¬éœ€è¦å®šä¹‰ä¸€ä¸ª<code>predict</code>æ¥å£ï¼Œä»¥ä¾¿è®­ç»ƒå¥½æˆ‘ä»¬çš„ç¥ç»ç½‘ç»œä»¥åè¿›è¡Œæµ‹è¯•é›†çš„é¢„æµ‹ï¼š</p>
<pre><code class="language-python">def predict(X, Y, parameters):
    m = Y.shape[1]
    Y_predict = np.zeros((1, m))
    AL, caches = L_model_forward(X, parameters)

    for i in range(0, AL.shape[1]):
        if AL[0, i] &gt; 0.5:
            Y_predict[0, i] = 1
        else:
            Y_predict[0, i] = 0

    print(&quot;å‡†ç¡®åº¦ä¸º:&quot;, 100 - np.mean(np.abs(Y - Y_predict)) * 100, &quot;%&quot;)
    return Y_predict
</code></pre>
<h3 id="ä¸‹é¢æ˜¯å®Œæ•´çš„ä»£ç ">ä¸‹é¢æ˜¯å®Œæ•´çš„ä»£ç ï¼š</h3>
<pre><code class="language-python">import numpy as np
from lr_utils import load_dataset
import matplotlib.pyplot as plt
from c9 import sigmoid, sigmoid_backward, relu, relu_backward

train_set_x, train_set_y, test_set_x, test_set_y, classes = load_dataset()

train_set_x = train_set_x.reshape(train_set_x.shape[0], -1).T
test_set_x = test_set_x.reshape(test_set_x.shape[0], -1).T

train_set_x = train_set_x / 255
test_set_x = test_set_x / 255


def initialize_parameters(dims):
    L = len(dims)
    parameters = {}
    for l in range(1, L):
        parameters['W' + str(l)] = np.random.randn(dims[l], dims[l-1]) * np.sqrt(1 / dims[l - 1])
        parameters['b'+ str(l)] = np.zeros((dims[l], 1))
    return parameters


def linear_forward(A, W, b):
    Z = np.dot(W, A) + b
    linear_cache = (A, W, b)
    return Z, linear_cache


def activation_forward(A_pre, W, b, activation):
    if activation == 'relu':
        Z, linear_cache = linear_forward(A_pre, W, b)
        A, activation_cache = relu(Z)
    elif activation == 'sigmoid':
        Z, linear_cache = linear_forward(A_pre, W, b)
        A, activation_cache = sigmoid(Z)

    cache = (linear_cache, activation_cache)
    return A, cache


def L_model_forward(X, parameters):
    caches = []
    A = X
    L = len(parameters) // 2
    for l in range(1, L):
        A_prev = A
        A, cache = activation_forward(A_prev, parameters['W' + str(l)], parameters['b' + str(l)], 'relu')
        caches.append(cache)

    AL, cache = activation_forward(A, parameters['W' + str(L)], parameters['b' + str(L)], 'sigmoid')
    caches.append(cache)

    return AL, caches


def cost_compute(AL, Y):
    m = Y.shape[1]
    cost = (-1 / m) * np.sum(np.multiply(Y, np.log(AL)) + np.multiply((1 - Y), np.log(1 - AL)))
    cost = np.squeeze(cost)

    return cost


def linear_backward(dZ, cache):
    A_prev, W, b = cache
    m = A_prev.shape[1]
    dW = np.dot(dZ, A_prev.T) / m
    db = np.sum(dZ, axis=1, keepdims=True) / m
    dA_prev = np.dot(W.T, dZ)

    return dA_prev, dW, db


def activation_backward(dA, cache, activation):
    linear_cache, activation_cache = cache
    if activation == 'relu':
        dZ = relu_backward(dA, activation_cache)
        dA_prev, dW, db = linear_backward(dZ, linear_cache)
    elif activation == 'sigmoid':
        dZ = sigmoid_backward(dA, activation_cache)
        dA_prev, dW, db = linear_backward(dZ, linear_cache)

    return dA_prev, dW, db


def L_model_backward(AL, Y, caches):
    grads = {}
    L = len(caches)
    m = AL.shape[1]
    Y = Y.reshape(AL.shape)
    dAL = -(np.divide(Y, AL) - np.divide((1 - Y), (1 - AL)))

    current_cache = caches[L - 1]
    grads['dA'+str(L)], grads['dW'+str(L)], grads['db'+str(L)] = activation_backward(dAL, current_cache, 'sigmoid')

    for l in reversed(range(L - 1)):
        current_cache = caches[l]
        grads['dA'+str(l + 1)], grads['dW'+str(l + 1)], grads['db'+str(l + 1)] = activation_backward(grads['dA'+str(l + 2)], current_cache, 'relu')

    return grads


def up_parameters(parameters, grads, learning_rate):
    L = len(parameters) // 2
    for l in range(L):
        parameters['W'+str(l+1)] = parameters['W'+str(l+1)] - learning_rate * grads['dW'+str(l+1)]
        parameters['b'+str(l+1)] = parameters['b'+str(l+1)] - learning_rate * grads['db'+str(l+1)]
    return parameters


def L_model(X, Y, dims, learning_rate, num_iternations, print_cost=False, isPlot=False):
    parameters = initialize_parameters(dims)
    costs = []
    for i in range(num_iternations):
        AL, caches = L_model_forward(X, parameters)
        cost = cost_compute(AL, Y)
        grads = L_model_backward(AL, Y, caches)
        parameters = up_parameters(parameters, grads, learning_rate)

        if i % 100 == 0:
            costs.append(cost)
            if print_cost:
                print(&quot;ç¬¬&quot;, i + 100, &quot;æ¬¡è¿­ä»£ï¼Œæˆæœ¬å€¼ä¸º:&quot;, np.squeeze(cost))

    if isPlot:
        plt.plot(np.squeeze(costs))
        plt.ylabel('cost')
        plt.xlabel('iterations (per tens)')
        plt.title(&quot;Learning rate =&quot; + str(learning_rate))
        plt.show()
    return parameters


def predict(X, Y, parameters):
    m = Y.shape[1]
    Y_predict = np.zeros((1, m))
    AL, caches = L_model_forward(X, parameters)

    for i in range(0, AL.shape[1]):
        if AL[0, i] &gt; 0.5:
            Y_predict[0, i] = 1
        else:
            Y_predict[0, i] = 0

    print(&quot;å‡†ç¡®åº¦ä¸º:&quot;, 100 - np.mean(np.abs(Y - Y_predict)) * 100, &quot;%&quot;)
    return Y_predict


dims = [12288, 20, 7, 5, 1]
parameters = L_model(train_set_x, train_set_y, dims, learning_rate=0.005, num_iternations=2000, print_cost=True, isPlot=True)

print('è®­ç»ƒé›†å‡†ç¡®åº¦ï¼š')
Y_train_predict = predict(train_set_x, train_set_y, parameters)
print('~~~~~~~~~~~~~~~~~~')
print('æµ‹è¯•é›†å‡†ç¡®åº¦ï¼š')
Y_test_predict = predict(test_set_x, test_set_y, parameters)
</code></pre>
<h3 id="è®­ç»ƒç»“æœ">è®­ç»ƒç»“æœ</h3>
<pre><code>ç¬¬ 100 æ¬¡è¿­ä»£ï¼Œæˆæœ¬å€¼ä¸º: 0.6994873707865432
ç¬¬ 200 æ¬¡è¿­ä»£ï¼Œæˆæœ¬å€¼ä¸º: 0.6806558525294543
ç¬¬ 300 æ¬¡è¿­ä»£ï¼Œæˆæœ¬å€¼ä¸º: 0.6705312328121265
ç¬¬ 400 æ¬¡è¿­ä»£ï¼Œæˆæœ¬å€¼ä¸º: 0.6619037949674021
ç¬¬ 500 æ¬¡è¿­ä»£ï¼Œæˆæœ¬å€¼ä¸º: 0.6536510177438547
ç¬¬ 600 æ¬¡è¿­ä»£ï¼Œæˆæœ¬å€¼ä¸º: 0.6446148155840906
ç¬¬ 700 æ¬¡è¿­ä»£ï¼Œæˆæœ¬å€¼ä¸º: 0.634667166888006
ç¬¬ 800 æ¬¡è¿­ä»£ï¼Œæˆæœ¬å€¼ä¸º: 0.6221946752377217
ç¬¬ 900 æ¬¡è¿­ä»£ï¼Œæˆæœ¬å€¼ä¸º: 0.6056921109383494
ç¬¬ 1000 æ¬¡è¿­ä»£ï¼Œæˆæœ¬å€¼ä¸º: 0.5842339799894992
ç¬¬ 1100 æ¬¡è¿­ä»£ï¼Œæˆæœ¬å€¼ä¸º: 0.5575090729216234
ç¬¬ 1200 æ¬¡è¿­ä»£ï¼Œæˆæœ¬å€¼ä¸º: 0.5265284524914055
ç¬¬ 1300 æ¬¡è¿­ä»£ï¼Œæˆæœ¬å€¼ä¸º: 0.4923067992292893
ç¬¬ 1400 æ¬¡è¿­ä»£ï¼Œæˆæœ¬å€¼ä¸º: 0.45628570738509455
ç¬¬ 1500 æ¬¡è¿­ä»£ï¼Œæˆæœ¬å€¼ä¸º: 0.419308167347863
ç¬¬ 1600 æ¬¡è¿­ä»£ï¼Œæˆæœ¬å€¼ä¸º: 0.38715877890532724
ç¬¬ 1700 æ¬¡è¿­ä»£ï¼Œæˆæœ¬å€¼ä¸º: 0.355732703783392
ç¬¬ 1800 æ¬¡è¿­ä»£ï¼Œæˆæœ¬å€¼ä¸º: 0.3352978704494966
ç¬¬ 1900 æ¬¡è¿­ä»£ï¼Œæˆæœ¬å€¼ä¸º: 0.30310463706295426
ç¬¬ 2000 æ¬¡è¿­ä»£ï¼Œæˆæœ¬å€¼ä¸º: 0.29058149758066887
è®­ç»ƒé›†å‡†ç¡®åº¦ï¼š
å‡†ç¡®åº¦ä¸º: 97.12918660287082 %
~~~~~~~~~~~~~~~~~~
æµ‹è¯•é›†å‡†ç¡®åº¦ï¼š
å‡†ç¡®åº¦ä¸º: 74.0 %
</code></pre>
<p><img src="https://raw.githubusercontent.com/Tudouvvv/Pic_path/master/%E6%9C%80%E7%BB%88%E7%9A%84%E6%9B%B2%E7%BA%BF.png" alt=""></p>
<p>ç”±äºæˆ‘ä»¬æ¯æ¬¡çš„å‚æ•°éƒ½æ˜¯éšæœºåˆå§‹åŒ–çš„ï¼Œæ‰€ä»¥è®­ç»ƒçš„æ¯ä¸€æ¬¡çš„ç»“æœéƒ½æ˜¯ä¸ä¸€æ ·çš„ï¼Œä½†æ˜¯ç›¸æ¯”è¾ƒä¸Šæ¬¡ä½¿ç”¨logesticå›å½’70%çš„å‡†ç¡®åº¦ï¼Œè¿™æ¬¡çš„74%æœ‰ä¸€ç‚¹ç‚¹ä¸Šå‡ã€‚(ä½†æ˜¯æœ‰çš„æ—¶å€™ä¹Ÿæœ‰ä¸å¥½çš„æƒ…å†µ- -)</p>
<h1 id="å·ç§¯ç¥ç»ç½‘ç»œ">å·ç§¯ç¥ç»ç½‘ç»œ</h1>
<p>å·ç§¯ç¥ç»ç½‘ç»œç›¸æ¯”è¾ƒå…¨è¿æ¥çš„ç¥ç»ç½‘ç»œï¼Œå¯¹å›¾åƒæ›´åŠ å‹å¥½ã€‚</p>
<ol>
<li>
<p>å·ç§¯ç¥ç»ç½‘ç»œä¸­ï¼Œæœ€é‡è¦çš„å°±æ˜¯å·ç§¯æ ¸(filter)ï¼Œä½¿ç”¨å·ç§¯æ ¸åœ¨å›¾ç‰‡ä¸Šç§»åŠ¨åšå·ç§¯è¿ç®—ï¼Œå¾—åˆ°æ–°çš„çŸ©é˜µ</p>
</li>
<li>
<p>ä½¿ç”¨ä¸åŒçš„å·ç§¯æ ¸ï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°ä¸åŒçš„è¾¹ç¼˜ç‰¹å¾</p>
</li>
<li>
<p>å·ç§¯æ ¸ä¸­çš„æ¯ä¸ªæ•°éƒ½æ˜¯ä¸€ä¸ªå‚æ•°ï¼Œæˆ‘ä»¬éœ€è¦åšçš„å°±æ˜¯é€šè¿‡ç¥ç»ç½‘ç»œå»å­¦ä¹ è¿™äº›å‚æ•°</p>
</li>
<li>
<p>å·ç§¯ä»¥åçš„ç»´åº¦ X =  (N - F) + 1ï¼Œè¿™æ ·å·ç§¯ä»¥åæœ‰ä¸¤ä¸ªç¼ºç‚¹ï¼š1ã€æ¯æ¬¡å·ç§¯å®Œä»¥åå›¾åƒä¼šç¼©å°ï¼›2ã€å›¾åƒçš„è§’è½å’Œè¾¹ç¼˜ä¿¡æ¯ä¼šä¸¢å¤±ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨paddingï¼Œåœ¨å›¾åƒçš„è¾¹ç¼˜è¿›è¡Œå¡«å……ï¼Œè¿™æ ·å·ç§¯ä»¥åçš„ç»´åº¦ä¸º X = (N + 2P - F) + 1ã€‚è‡³äºå¡«å……å¤šå°‘ä¸ªåƒç´ ï¼Œä¸€èˆ¬åˆ†ä¸ºValid å’Œ Sameï¼ŒValidå·ç§¯ä¸å¡«å……åƒç´ ï¼ŒSameå·ç§¯æ„å‘³ç€å·ç§¯ä»¥åå›¾ç‰‡çš„å¤§å°ä¸å˜ï¼Œå³ N = (N + 2P - F) + 1ï¼Œæ­¤æ—¶ï¼ŒP = (F - 1)/2ï¼Œæ‰€ä»¥å·ç§¯æ ¸çš„ç»´åº¦ä¸€èˆ¬é€‰æ‹©å¥‡æ•°ï¼Œä¸€æ–¹é¢å¯èƒ½æ˜¯ä¸ºäº†Paddingï¼Œå¦ä¸€æ–¹é¢æ­¤æ—¶çš„å·ç§¯æ ¸ä¼šæœ‰ä¸€ä¸ªä¸­å¿ƒç‚¹ã€‚</p>
</li>
<li>
<p>å·ç§¯æ ¸ç§»åŠ¨çš„æ­¥é•¿ä¹Ÿæ˜¯ä¸€ä¸ªå‚æ•°ï¼Œæ­¤æ—¶çš„è¾“å‡ºç»´åº¦ X = (N + 2P - F)/S + 1ï¼Œã€å¦‚æœä¸æ˜¯æ•´æ•°ï¼Œå‘ä¸‹å–æ•´ã€‘ã€‚</p>
</li>
<li>
<p>äº’ç›¸å…³å’Œå·ç§¯ï¼šæ˜¯å¦æ—‹è½¬é•œåƒï¼Œä½†æ˜¯å¯¹äºå·ç§¯ç¥ç»ç½‘ç»œæ¥è¯´ï¼Œæˆ‘ä»¬æŠŠäº’ç›¸å…³çš„æ•°å­¦è¿ç®—å°±å«åšå·ç§¯</p>
</li>
<li>
<p>å¯¹ä¸€å¼ å›¾ç‰‡æ¥è¯´ï¼Œæœ‰ä¸‰ä¸ªé€šé“ï¼Œ<code>è€Œå·ç§¯æ ¸çš„é€šé“æ•°å¿…é¡»ä¸å›¾ç‰‡çš„é€šé“æ•°ä¸€è‡´</code>ã€‚æ¯”å¦‚å›¾ç‰‡æ˜¯6 Ã— 6 Ã— 3ï¼Œå¦‚æœå·ç§¯æ ¸ä¸º 3 Ã— 3 Ã— 3ï¼Œæ­¤æ—¶è¿›è¡Œå·ç§¯æ—¶ï¼Œæ¯ä¸ªé€šé“åˆ†åˆ«å·ç§¯ï¼Œç„¶åå°†æ¯ä¸ªé€šé“å·ç§¯åçš„ç»“æœç›¸åŠ ï¼Œå¾—åˆ°ä¸€ä¸ª4 Ã— 4 Ã— 1çš„è¾“å‡ºç»“æœã€‚è¿™æ ·ç”¨å¤šä¸ª3 Ã— 3 Ã— 3çš„å·ç§¯æ ¸è¿›è¡Œå·ç§¯ï¼Œå¾—åˆ°å¤šä¸ª4 Ã— 4çš„è¾“å‡ºç»“æœï¼Œç›¸å½“äºå¤šä¸ªchannelsã€‚</p>
</li>
<li>
<p>å·ç§¯ä»¥åå¾—åˆ°4 Ã— 4çš„è¾“å‡ºç»“æœï¼Œæ­¤æ—¶å†åŠ ä¸Šåå·®ï¼Œç›¸å½“äº Z = W*X + bï¼Œç„¶ååº”ç”¨æ¿€æ´»å‡½æ•°ï¼ŒA = g(Z)ï¼Œæœ€åæŠŠè¿™äº›æ¿€æ´»ä»¥åçš„ç»“æœå †å åœ¨ä¸€èµ·ï¼Œè¿›è¡Œä¸‹ä¸€å±‚çš„å·ç§¯è¿ç®—ã€‚è¿™æ ·åšçš„å¥½å¤„å°±æ˜¯æå¤§çš„å‡å°‘äº†å‚æ•°çš„ä¸ªæ•°ï¼Œé¿å…è¿‡æ‹Ÿåˆã€‚</p>
</li>
<li>
<p>é™¤äº†å·ç§¯å±‚ï¼Œä¸€èˆ¬ä¹Ÿç»å¸¸ä½¿ç”¨æ± åŒ–å±‚ï¼Œæ¥ç¼©å‡æ¨¡å‹å¤§å°ï¼Œæé«˜è®¡ç®—é€Ÿåº¦ã€‚æ± åŒ–å±‚æœ‰ä¸¤ç§æ–¹æ³•ï¼Œä¸€ç§æ˜¯Max Poolingï¼Œé€‰å–åŒºåŸŸå†…çš„æœ€å¤§å€¼ï¼Œè¿™æ ·åšå¯ä»¥è§£é‡Šä¸ºå¦‚æœè¿‡æ»¤å™¨æå–åˆ°äº†æŸä¸ªç‰¹å¾ï¼Œé‚£ä¹ˆä¿ç•™å…¶æœ€å¤§å€¼ã€‚è¿˜æœ‰ä¸€ç§æ˜¯Average Poolingï¼Œé€‰å–å¹³å‡å€¼ï¼Œä¸è¿‡ä¸æ˜¯ç»å¸¸ä½¿ç”¨ã€‚æ± åŒ–å±‚æ²¡æœ‰éœ€è¦å­¦ä¹ çš„å‚æ•°ï¼Œæ± åŒ–åé€šé“æ•°ä¸ä¼šæ”¹å˜ã€‚æ± åŒ–å±‚éœ€è¦é€‰æ‹©filterçš„å¤§å°å’Œæ­¥é•¿ï¼Œä¸€èˆ¬éƒ½æ˜¯å–2ï¼Œè¿™ç§æƒ…å†µä¸‹ä¼šç¼©å°ä¸€åŠã€‚</p>
</li>
<li>
<p>å·ç§¯ç¥ç»ç½‘ç»œçš„ä¼˜ç‚¹ï¼šå‚æ•°å…±äº«å’Œç¨€ç–è¿æ¥</p>
</li>
</ol>
<h2 id="kerasä¸­å®šä¹‰å·ç§¯ç¥ç»ç½‘ç»œ">Kerasä¸­å®šä¹‰å·ç§¯ç¥ç»ç½‘ç»œ</h2>
<p>åœ¨Kerasä¸­ï¼Œå®šä¹‰ä¸€ä¸ªå·ç§¯ç¥ç»ç½‘ç»œæ˜¯éå¸¸ç®€å•çš„ï¼š</p>
<pre><code>from lr_utils import load_dataset
from keras import optimizers
import matplotlib.pyplot as plt
from keras import models
from keras import layers

train_set_x, train_set_y, test_set_x, test_set_y, classes = load_dataset()

train_set_x = train_set_x / 255
test_set_x = test_set_x / 255

train_set_y = train_set_y.T
test_set_y = test_set_y.T

model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(1, activation='sigmoid'))

model.compile(optimizer=optimizers.sgd(lr=0.005),
              loss='binary_crossentropy',
              metrics=['accuracy'])


history = model.fit(train_set_x, train_set_y, epochs=2000, batch_size=209)
train_loss, train_acc = model.evaluate(train_set_x, train_set_y)
test_loss, test_acc = model.evaluate(test_set_x, test_set_y)

print('train_loss', train_loss, 'train_acc', train_acc)
print('test_loss', test_loss, 'test_acc', test_acc)

history_dict = history.history

loss_values = history_dict['loss']
epochs = range(1, len(loss_values) + 1)
plt.plot(epochs, loss_values, 'b', label='Train loss')
plt.title('Training loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.show()

</code></pre>
<p>å…·ä½“çš„ç»“æ„æ˜¯è·Ÿä¹¦ä¸Šçš„ä¾‹å­ä¸€æ¨¡ä¸€æ ·ï¼Œå¯ä»¥çœ‹ä¸€äº›è¿™ä¸ªå·ç§¯ç¥ç»ç½‘ç»œçš„ç»“æ„ï¼š</p>
<pre><code>Using TensorFlow backend.
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
conv2d_1 (Conv2D)            (None, 62, 62, 32)        896
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 31, 31, 32)        0
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 29, 29, 64)        18496
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 14, 14, 64)        0
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 12, 12, 64)        36928
_________________________________________________________________
flatten_1 (Flatten)          (None, 9216)              0
_________________________________________________________________
dense_1 (Dense)              (None, 64)                589888
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 65
=================================================================
Total params: 646,273
Trainable params: 646,273
Non-trainable params: 0
</code></pre>
<p>è¿™æ˜¯å®ƒçš„è®­ç»ƒç»“æœï¼Œè®²é“ç†æµ‹è¯•é›†å‡†ç¡®åº¦ç«Ÿç„¶è¾¾åˆ°äº†84%ï¼Œä¸è¿‡æŸå¤±å‡½æ•°æ›²çº¿æœ‰ç‚¹ä¸ç¨³å®šï¼š</p>
<pre><code>train_loss 0.17385125616520786 train_acc 0.93779904391777
test_loss 0.5197753620147705 test_acc 0.8399999928474426
</code></pre>
<p><img src="https://raw.githubusercontent.com/Tudouvvv/Pic_path/master/keras_cat.png" alt=""></p>
<p>åé¢ä¼šå°è¯•K-æŠ˜äº¤å‰éªŒè¯æˆ–è€…åŠ å…¥æ­£åˆ™é¡¹ã€‚</p>
<blockquote>
<blockquote>
<blockquote>
<p>å¾…ç»­</p>
</blockquote>
</blockquote>
</blockquote>
 </p>
                      </div>
                  </div>

                  <div class="row">
                      <div class="col-md-12 animate-box">
                          
                              <div class="next-post">
                                  <div class="next">ä¸‹ä¸€ç¯‡</div>
                                  <a href="https://tudouvvv.github.io//post/ç¥ç»ç½‘ç»œä¸æ·±åº¦å­¦ä¹ -ç¬¬äºŒå‘¨ä½œä¸š">
                                      <h3 class="post-title">
                                          ç¥ç»ç½‘ç»œä¸æ·±åº¦å­¦ä¹ -ç¬¬äºŒå‘¨ä½œä¸š
                                      </h3>
                                  </a>
                              </div>
                          
                      </div>
                  </div>

                  <div class="row">
                      <div class="col-md-12 animate-box">
                          
                      </div>
                  </div>
              </div>

          </article>
      </div>
  </div>

    
<footer id="fh5co-footer">
  <p>Powered by <a href="https://github.com/tudouvvv" target="_blank">Tudouvvv</a></p>
</footer>


    
<!-- jQuery -->
<script src="https://tudouvvv.github.io//media/scripts/_vendors/jquery.min.js"></script>
<!-- jQuery Easing -->
<script src="https://tudouvvv.github.io//media/scripts/_vendors/jquery.easing.1.3.js"></script>
<!-- Bootstrap -->
<script src="https://tudouvvv.github.io//media/scripts/_vendors/bootstrap.min.js"></script>
<!-- Waypoints -->
<script src="https://tudouvvv.github.io//media/scripts/_vendors/jquery.waypoints.min.js"></script>
<!-- Main JS -->
<script src="https://tudouvvv.github.io//media/scripts/_vendors/main.js"></script>
<!-- Md5 Min JS -->
<script src="https://tudouvvv.github.io//media/scripts/_vendors/md5.min.js"></script>

<script type="application/javascript">
    hljs.initHighlightingOnLoad();
</script>




  </body>
</html>
